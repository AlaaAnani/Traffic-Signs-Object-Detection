{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0c179d6818f0fa2f4801ff1ce357067389301277b14d7a89b8f0a5debb292dfaf",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Steps for Red-and-Yellow Road Signs Detection\n",
    "\n",
    "## 1. Red Color Segmentation\n",
    "\n",
    "An important thing I noticed is that all road signs of interest are bounded by red, making red detection more important than yellow. I first segment the color red in the image by detecting pixels lying in a certain red range I defined using the `cv2.inRange` function. Then I zero all other non-red pixels to only leave the red pixels being non-zero in the resulting segmented image `red_segmented_bgr`. \n",
    "\n",
    "## 2. Binarizing Red-Segmented Images\n",
    "\n",
    "Then I use `cv2.threshold` function to binarize the image, which returns a new gray image of pixels with binary values where the red pixels in `red_segmented_bgr` are set to 1 and the rest are 0. The resulting image in called `binary_img`.\n",
    "\n",
    "## 3. Getting Proposed Regions\n",
    "\n",
    "Using the function `cv2.findContours`, I get all the bounding boxes in the simple resulting `binary_img` from the previous step. Few of these rectangles will definitely contain our desired objects (red+yellow road signs) since they bound any red-containing region in the image. This method is much more efficient than another method I tried earlier, which was Selective Search. The proposed number of regions proposed decreased from around 7k+ in Selective Search to few tens or hundreds in this method, depending on how many red regions are found in the image.\n",
    "\n",
    "## 4. Running a Binary CNN-Classifier on Proposed Regions\n",
    "\n",
    "To know which of the proposed regions exactly contains the desired road signs, I run a pre-trained classifier on all of thenm first. Then, I order them descensingly according to their probabilities outputted from the classifier. Then, I take the n-highest regions passing a certain threshold (set as `0.9` by default, could be changed) to be containing the detected object. Green rectangles show a correctly detected object by the classifier, while blue ones show all proposed regions in general.\n",
    "\n",
    "# Training a Binary Classifier\n",
    "\n",
    "**Dataset**: I made a dataset of 2 classes composed of 513 images by taking cropped screenshots from the given set of sign images. The `1` class contains all given signs of interest and scraped red-and-yellow signs from the internet to make the set more diverse. The `0` class is constructed through running Selective Search and also getting the cropped regions suggested by step `3` and humanly specifiying which of them belongs to class `0`. Selective Search provided much diversity since it proposes many regions, not only red-containing regions. Regions from step `3` served as a very strong basis for the model to be robust again red regions that are not red-and-yellow road signs. The dataset is the folder `dataset/`.\n",
    "\n",
    "**Model Architecture:** found in `cnn_model.py` and the best model is saved as `cnn_model_2`. \n",
    "**Loss:** Binary cross entropy loss function is used.\n",
    "\n",
    "# Results\n",
    "\n",
    "`Number of correct detections = 34` with regions covering nearly 100% of the object\n",
    "\n",
    "`Number of false detections = 0`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "from skimage.io import imread, imshow, imsave\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from tensorflow import keras\n",
    "from object_detection import segment_red, binarize_segments, get_proposed_rectangles, detect_road_signs\n",
    "from utils import show\n",
    "base = \"Images/\"\n",
    "signs_model = keras.models.load_model('cnn_model_2')\n",
    "titles = ['Original Image', 'Binary Red-Segmented Image', 'All Proposed Rectangles', 'Detected Road Signs = ']\n",
    "images_paths = [base+entry for entry in os.listdir(base)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, path in enumerate(images_paths):\n",
    "    image = cv2.imread(path)\n",
    "    red_segmented_bgr = segment_red(image)\n",
    "    binary_img = binarize_segments(red_segmented_bgr)\n",
    "    rects = get_proposed_rectangles(binary_img)\n",
    "    output_w_all_rects, final_output, detected_signs, _ = detect_road_signs(signs_model, image, rects)\n",
    "    images = [image, binary_img, output_w_all_rects, final_output]\n",
    "    titles[2] = 'Overall Proposed Bounding Rectangles = ' + str(len(rects))\n",
    "    titles[3] = 'Detected Road Signs = ' + str(detected_signs)\n",
    "    show(2, 2, images, titles, save=False, path=\"plots/\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}